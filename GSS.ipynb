{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f9f2aad-c8c6-4e3f-bd8d-01f7b3a7a3c7",
   "metadata": {},
   "source": [
    "# U-net Implementation for Guitar String Separation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4084e0ab-061a-4908-a49a-80fc06cdb34a",
   "metadata": {},
   "source": [
    "Firstly, you need to install librosa. If you don't have librosa, make sure you run the requirements.txt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e633f61-b6e5-48fa-998e-bc8d4124796f",
   "metadata": {
    "execution": {
     "iopub.status.idle": "2023-08-22T14:40:04.606500Z",
     "shell.execute_reply": "2023-08-22T14:40:04.605443Z",
     "shell.execute_reply.started": "2023-08-22T14:40:01.005900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: librosa in /usr/local/lib/python3.9/dist-packages (0.10.1)\n",
      "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.9/dist-packages (from librosa) (1.0.4)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.9/dist-packages (from librosa) (0.12.1)\n",
      "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.9/dist-packages (from librosa) (1.2.0)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.9/dist-packages (from librosa) (0.3)\n",
      "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.9/dist-packages (from librosa) (1.7.0)\n",
      "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.9/dist-packages (from librosa) (0.3.6)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.9/dist-packages (from librosa) (4.4.0)\n",
      "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.9/dist-packages (from librosa) (0.57.1)\n",
      "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.9/dist-packages (from librosa) (1.9.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.9/dist-packages (from librosa) (5.1.1)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.9/dist-packages (from librosa) (1.1.2)\n",
      "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /usr/local/lib/python3.9/dist-packages (from librosa) (1.23.4)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.9/dist-packages (from librosa) (3.0.0)\n",
      "Requirement already satisfied: llvmlite<0.41,>=0.40.0dev0 in /usr/local/lib/python3.9/dist-packages (from numba>=0.51.0->librosa) (0.40.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from pooch>=1.0->librosa) (2.28.2)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.9/dist-packages (from pooch>=1.0->librosa) (2.6.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from pooch>=1.0->librosa) (23.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.20.0->librosa) (3.1.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.9/dist-packages (from soundfile>=0.12.1->librosa) (1.15.1)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.9/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2019.11.28)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a8e75ca-67cb-43d2-b29e-c0f7674bfc1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-24T15:37:20.209261Z",
     "iopub.status.busy": "2023-08-24T15:37:20.208465Z",
     "iopub.status.idle": "2023-08-24T15:37:20.547653Z",
     "shell.execute_reply": "2023-08-24T15:37:20.545474Z",
     "shell.execute_reply.started": "2023-08-24T15:37:20.209215Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'librosa'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlibrosa\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras \n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'librosa'"
     ]
    }
   ],
   "source": [
    "#Importing the essential libraries\n",
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "from tensorflow import keras \n",
    "import matplotlib.pyplot as plt\n",
    "from keras.callbacks import ReduceLROnPlateau\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c1ab14-112f-4b9d-bfc9-4ce9f61a3d66",
   "metadata": {},
   "source": [
    "### We are using U-net model which is based on the following two papers:\n",
    "1. \"Singing Voice Separation with Deep U-Net Convolutional Networks\" by Jansson et al., 2017\n",
    "2. \"U-Net: Convolutional Networks for Biomedical Image Segmentation\" by Ronneberger et al., 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "377454f8-657c-41fd-ad3e-f75b60db83ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-22T14:40:08.085231Z",
     "iopub.status.busy": "2023-08-22T14:40:08.084994Z",
     "iopub.status.idle": "2023-08-22T14:40:08.103657Z",
     "shell.execute_reply": "2023-08-22T14:40:08.102662Z",
     "shell.execute_reply.started": "2023-08-22T14:40:08.085205Z"
    }
   },
   "outputs": [],
   "source": [
    "# Model Creation\n",
    "\n",
    "def unet(hyper_params,\n",
    "         input=keras.Input((512, 2**7, 1))): \n",
    "  # encoder\n",
    "  x = input\n",
    "  encoder_layers = []\n",
    "  for n_layer in range(hyper_params['NUM_BLOCKS']):\n",
    "    num_filters = 2 ** n_layer * hyper_params['FILTER_MULTIPLIER']\n",
    "    x = keras.layers.Conv2D(num_filters, 5, strides=2, padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    if hyper_params['DROPOUT_ENCODER'][n_layer]: x = keras.layers.Dropout(hyper_params['DROPOUT_RATE'])(x)\n",
    "    x = keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "    encoder_layers.append(x)\n",
    "\n",
    "  # decoder\n",
    "  for n_layer in range(hyper_params['NUM_BLOCKS']-1):\n",
    "    if not n_layer == 0: x = keras.layers.Concatenate(axis=3)([x, encoder_layers[hyper_params['NUM_BLOCKS'] - 1 - n_layer]])\n",
    "    num_filters = 2 ** (hyper_params['NUM_BLOCKS'] - 1 - n_layer) * hyper_params['FILTER_MULTIPLIER']\n",
    "    x = keras.layers.Conv2DTranspose(num_filters, 5, strides=2, padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    if hyper_params['DROPOUT_DECODER'][n_layer]: x = keras.layers.Dropout(hyper_params['DROPOUT_RATE'])(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "\n",
    "  output = keras.layers.Concatenate(axis=3)([x, encoder_layers[-hyper_params['NUM_BLOCKS']]])\n",
    "  output = keras.layers.Conv2DTranspose(1, 5, strides=2, padding='same')(output)\n",
    "  output = keras.layers.Activation('relu')(output)\n",
    "\n",
    "  # mask\n",
    "  if hyper_params['MASK']:\n",
    "    output = keras.layers.multiply([input, output])\n",
    "\n",
    "  model = keras.Model(inputs=input, outputs=output)\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08265286-5ddd-4e07-95b5-07ce26783ec9",
   "metadata": {},
   "source": [
    "## Computing the Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2370eb03-d71d-4f04-becd-9e17bf8ba471",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-22T14:40:08.107486Z",
     "iopub.status.busy": "2023-08-22T14:40:08.107249Z",
     "iopub.status.idle": "2023-08-22T14:40:08.115351Z",
     "shell.execute_reply": "2023-08-22T14:40:08.114568Z",
     "shell.execute_reply.started": "2023-08-22T14:40:08.107461Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_SDR_frame(true_frame, predicted_frame):\n",
    "    numerator = np.sum(true_frame**2)\n",
    "    denominator = np.sum((true_frame - predicted_frame)**2)\n",
    "    return 10 * np.log10(numerator / denominator)\n",
    "\n",
    "def compute_SIR_frame(true_frame, predicted_frame):\n",
    "    interference = true_frame - (np.dot(true_frame, predicted_frame) / np.dot(predicted_frame, predicted_frame)) * predicted_frame\n",
    "    numerator = np.sum(true_frame**2)\n",
    "    denominator = np.sum(interference**2)\n",
    "    return 10 * np.log10(numerator / denominator)\n",
    "\n",
    "def compute_SAR_frame(true_frame, predicted_frame):\n",
    "    artifacts = predicted_frame - (np.dot(predicted_frame, true_frame) / np.dot(true_frame, true_frame)) * true_frame\n",
    "    interference = true_frame - (np.dot(true_frame, predicted_frame) / np.dot(predicted_frame, predicted_frame)) * predicted_frame\n",
    "    numerator = np.sum((true_frame + interference)**2)\n",
    "    denominator = np.sum(artifacts**2)\n",
    "    return 10 * np.log10(numerator / denominator)\n",
    "\n",
    "def compute_metric_for_signal(true_signal, predicted_signal, metric_func):\n",
    "    # Reshaping to 2D (num_frames, frame_length)\n",
    "    true_signal = true_signal.reshape(true_signal.shape[0], -1)\n",
    "    predicted_signal = predicted_signal.reshape(predicted_signal.shape[0], -1)\n",
    "    \n",
    "    metric_values = [metric_func(true_frame, predicted_frame) for true_frame, predicted_frame in zip(true_signal, predicted_signal)]\n",
    "    return np.mean(metric_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "703186e8-6bd5-4715-94bb-048b64a44b1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-22T14:40:08.116822Z",
     "iopub.status.busy": "2023-08-22T14:40:08.116547Z",
     "iopub.status.idle": "2023-08-22T14:40:08.120844Z",
     "shell.execute_reply": "2023-08-22T14:40:08.119897Z",
     "shell.execute_reply.started": "2023-08-22T14:40:08.116796Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize the Directory\n",
    "\n",
    "resized_input_dir = \"/notebooks/IN+AUG\"\n",
    "resized_target_dir = \"/notebooks/tar + AUG\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf48838b-ca58-4da0-b7a2-58a6d64e709a",
   "metadata": {},
   "source": [
    "### Checks for Inspecting the Spectrograms to know the mean and the shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae1a1039-cc51-4b84-9466-8d8761c44d22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-22T14:40:31.864252Z",
     "iopub.status.busy": "2023-08-22T14:40:31.863868Z",
     "iopub.status.idle": "2023-08-22T14:40:31.870170Z",
     "shell.execute_reply": "2023-08-22T14:40:31.869276Z",
     "shell.execute_reply.started": "2023-08-22T14:40:31.864225Z"
    }
   },
   "outputs": [],
   "source": [
    "def inspect_saved_spectrograms(spectrogram_dir, limit=5):\n",
    "    \"\"\"\n",
    "    Loads and prints details or content of saved spectrograms.\n",
    "    \n",
    "    Parameters:\n",
    "    - spectrogram_dir: Path to directory containing saved spectrogram numpy files.\n",
    "    - limit: Number of spectrogram files to inspect. Default is 5.\n",
    "    \"\"\"\n",
    "    files = sorted(os.listdir(spectrogram_dir))\n",
    "    for i, file in enumerate(files[:limit]):\n",
    "        file_path = os.path.join(spectrogram_dir, file)\n",
    "        spectrogram = np.load(file_path)\n",
    "        \n",
    "        print(f\"Spectrogram for {file}:\")\n",
    "        print(f\"Shape: {spectrogram.shape}\")\n",
    "        print(f\"Max: {np.max(spectrogram)}, Min: {np.min(spectrogram)}, Mean: {np.mean(spectrogram)}\")\n",
    "        print(\"\\n\" + \"=\"*40 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60920d2e-5e68-486b-b0ca-ae187af94ff5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-22T14:40:32.749256Z",
     "iopub.status.busy": "2023-08-22T14:40:32.748888Z",
     "iopub.status.idle": "2023-08-22T14:40:32.909336Z",
     "shell.execute_reply": "2023-08-22T14:40:32.908315Z",
     "shell.execute_reply.started": "2023-08-22T14:40:32.749228Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spectrogram for 00_BN1-129-Eb_comp_mix.wav.npy:\n",
      "Shape: (512, 128, 1)\n",
      "Max: 22.248661041259766, Min: -57.23155212402344, Mean: -49.51835250854492\n",
      "\n",
      "========================================\n",
      "\n",
      "Spectrogram for 00_BN1-129-Eb_comp_mix_noise_injection.npy:\n",
      "Shape: (512, 128, 1)\n",
      "Max: 69.12982940673828, Min: -0.23467423021793365, Mean: 0.189961239695549\n",
      "\n",
      "========================================\n",
      "\n",
      "Spectrogram for 00_BN1-129-Eb_comp_mix_pitch_shifting.npy:\n",
      "Shape: (512, 128, 1)\n",
      "Max: 49.37890625, Min: -0.07383453845977783, Mean: 0.09082947671413422\n",
      "\n",
      "========================================\n",
      "\n",
      "Spectrogram for 00_BN1-129-Eb_comp_mix_time_stretching.npy:\n",
      "Shape: (512, 128, 1)\n",
      "Max: 64.82308197021484, Min: -0.116488978266716, Mean: 0.08924165368080139\n",
      "\n",
      "========================================\n",
      "\n",
      "Spectrogram for 00_BN1-129-Eb_solo_mix.wav.npy:\n",
      "Shape: (512, 128, 1)\n",
      "Max: 26.652942657470703, Min: -52.62190246582031, Mean: -42.67133331298828\n",
      "\n",
      "========================================\n",
      "\n",
      "Spectrogram for 00_BN1-129-Eb_comp_hex_cln.wav.npy:\n",
      "Shape: (512, 128, 1)\n",
      "Max: 15.900431632995605, Min: -64.6517105102539, Mean: -56.013648986816406\n",
      "\n",
      "========================================\n",
      "\n",
      "Spectrogram for 00_BN1-129-Eb_comp_hex_cln_noise_injection.npy:\n",
      "Shape: (512, 128, 1)\n",
      "Max: 36.26534652709961, Min: -0.13823123276233673, Mean: 0.10162001103162766\n",
      "\n",
      "========================================\n",
      "\n",
      "Spectrogram for 00_BN1-129-Eb_comp_hex_cln_pitch_shifting.npy:\n",
      "Shape: (512, 128, 1)\n",
      "Max: 33.71566390991211, Min: -0.08647729456424713, Mean: 0.0500447154045105\n",
      "\n",
      "========================================\n",
      "\n",
      "Spectrogram for 00_BN1-129-Eb_comp_hex_cln_time_stretching.npy:\n",
      "Shape: (512, 128, 1)\n",
      "Max: 28.97545051574707, Min: -0.10162876546382904, Mean: 0.04542741924524307\n",
      "\n",
      "========================================\n",
      "\n",
      "Spectrogram for 00_BN1-129-Eb_solo_hex_cln.wav.npy:\n",
      "Shape: (512, 128, 1)\n",
      "Max: 12.20644474029541, Min: -68.6136474609375, Mean: -58.05252456665039\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inspect_saved_spectrograms(resized_input_dir)\n",
    "inspect_saved_spectrograms(resized_target_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a7dd47-347d-436f-8623-ad4f26b67611",
   "metadata": {},
   "source": [
    "## Learning Rate Finder for efficient model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a3e30bf-e610-4552-8ac7-6b61ce288f75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-22T14:34:34.403237Z",
     "iopub.status.busy": "2023-08-22T14:34:34.402081Z",
     "iopub.status.idle": "2023-08-22T14:34:34.407249Z",
     "shell.execute_reply": "2023-08-22T14:34:34.406632Z",
     "shell.execute_reply.started": "2023-08-22T14:34:34.403207Z"
    }
   },
   "outputs": [],
   "source": [
    "class LearningRateFinder(keras.callbacks.Callback):\n",
    "    def __init__(self, min_lr=1e-6, max_lr=1e-1, steps_per_epoch=None, epochs=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.min_lr = min_lr\n",
    "        self.max_lr = max_lr\n",
    "        self.total_iterations = steps_per_epoch * epochs\n",
    "        self.iteration = 0\n",
    "        self.history = {}\n",
    "        \n",
    "    def clr(self):\n",
    "        \"\"\"Compute the current learning rate.\"\"\"\n",
    "        x = self.iteration / self.total_iterations \n",
    "        return self.min_lr + (self.max_lr-self.min_lr) * x\n",
    "        \n",
    "    def on_train_begin(self, logs=None):\n",
    "        \"\"\"Initialize the learning rate to the minimum value at the start of training.\"\"\"\n",
    "        logs = logs or {}\n",
    "        keras.backend.set_value(self.model.optimizer.lr, self.min_lr)\n",
    "        \n",
    "    def on_batch_end(self, epoch, logs=None):\n",
    "        \"\"\"Record the previous batch's statistics and update the learning rate.\"\"\"\n",
    "        logs = logs or {}\n",
    "        self.iteration += 1\n",
    "\n",
    "        self.history.setdefault('lr', []).append(keras.backend.get_value(self.model.optimizer.lr))\n",
    "        self.history.setdefault('iterations', []).append(self.iteration)\n",
    "\n",
    "        for k, v in logs.items():\n",
    "            self.history.setdefault(k, []).append(v)\n",
    "            \n",
    "        keras.backend.set_value(self.model.optimizer.lr, self.clr())\n",
    "\n",
    "\n",
    "def plot_lr_finder(history):\n",
    "    \"\"\"Plot the loss versus learning rate.\"\"\"\n",
    "    plt.plot(history['lr'], history['loss'])\n",
    "    plt.xscale('log')\n",
    "    plt.xlabel('Learning Rate')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Learning Rate Finder')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e2bb4c-29cd-43cd-90d5-b7ef687ca14e",
   "metadata": {},
   "source": [
    "## Normalize your spectrograms if not already normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc3828ca-d109-4a89-a1d8-412d83e15341",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-22T14:34:35.269684Z",
     "iopub.status.busy": "2023-08-22T14:34:35.268523Z",
     "iopub.status.idle": "2023-08-22T14:34:35.275723Z",
     "shell.execute_reply": "2023-08-22T14:34:35.274651Z",
     "shell.execute_reply.started": "2023-08-22T14:34:35.269636Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def normalize_spectrogram(spectrogram):\n",
    "    \"\"\"\n",
    "    Normalize the given spectrogram.\n",
    "    \n",
    "    :param spectrogram: numpy array of the spectrogram\n",
    "    :return: normalized spectrogram\n",
    "    \"\"\"\n",
    "    # Subtract the mean and divide by the standard deviation\n",
    "    normalized_spectrogram = (spectrogram - np.mean(spectrogram)) / np.std(spectrogram)\n",
    "    return normalized_spectrogram\n",
    "\n",
    "\n",
    "def normalize_spectrograms(input_dir, output_dir):\n",
    "    \"\"\"\n",
    "    Normalize all spectrograms in the input directory and save to the output directory.\n",
    "    \n",
    "    :param input_dir: directory containing the original spectrograms\n",
    "    :param output_dir: directory where normalized spectrograms will be saved\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    for file_name in os.listdir(input_dir):\n",
    "        if file_name.endswith('.npy'):\n",
    "            file_path = os.path.join(input_dir, file_name)\n",
    "            spectrogram = np.load(file_path)\n",
    "            normalized_spectrogram = normalize_spectrogram(spectrogram)\n",
    "            output_path = os.path.join(output_dir, file_name)\n",
    "            np.save(output_path, normalized_spectrogram)\n",
    "\n",
    "\n",
    "# Example usage: for mix\n",
    "# input_directory = \"/notebooks/mix/combined_mix_resize\"\n",
    "# output_directory = \"/notebooks/mix/norm_mix_resz\"\n",
    "# normalize_spectrograms(input_directory, output_directory)\n",
    "\n",
    "\n",
    "# input_directory_hex = \"/notebooks/hex/combined_hex_resize\"\n",
    "# output_directory_hex = \"/notebooks/hex/norm_hex_resz\"\n",
    "# normalize_spectrograms(input_directory_hex, output_directory_hex)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "200b17e2-8b18-4b79-af15-dc372190338f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-22T14:40:55.122182Z",
     "iopub.status.busy": "2023-08-22T14:40:55.121849Z",
     "iopub.status.idle": "2023-08-22T14:40:55.130291Z",
     "shell.execute_reply": "2023-08-22T14:40:55.129330Z",
     "shell.execute_reply.started": "2023-08-22T14:40:55.122157Z"
    }
   },
   "outputs": [],
   "source": [
    "input_files = sorted(os.listdir(resized_input_dir))\n",
    "target_files = sorted(os.listdir(resized_target_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a99314-a385-4fdf-a2e2-0cf546d19821",
   "metadata": {},
   "source": [
    "## Some sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2c8d400-a605-47b6-8838-92d17428ad53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-22T14:40:55.519878Z",
     "iopub.status.busy": "2023-08-22T14:40:55.519497Z",
     "iopub.status.idle": "2023-08-22T14:41:15.275535Z",
     "shell.execute_reply": "2023-08-22T14:41:15.274470Z",
     "shell.execute_reply.started": "2023-08-22T14:40:55.519852Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Function to determine the maximum shape from a list of .npy files\n",
    "def determine_max_shape(files, directory):\n",
    "    max_shape = (0, 0)\n",
    "    for f in files:\n",
    "        data_shape = np.load(os.path.join(directory, f)).shape\n",
    "        max_shape = (max(max_shape[0], data_shape[0]), max(max_shape[1], data_shape[1]))\n",
    "    return max_shape\n",
    "\n",
    "# Function to load and pad the numpy arrays\n",
    "def load_and_pad(file_path, max_shape):\n",
    "    data = np.load(file_path)\n",
    "    padding = [(0, max_shape[i] - data.shape[i]) for i in range(2)] + [(0,0)]  # the last padding is for the channel dimension\n",
    "    return np.pad(data, padding)\n",
    "\n",
    "max_input_shape = determine_max_shape(input_files, resized_input_dir)\n",
    "max_target_shape = determine_max_shape(target_files, resized_target_dir)\n",
    "# Here, I'm assuming that max_input_shape is same as max_target_shape, \n",
    "# if that's not the case you might need to pad them to a common maximum shape\n",
    "\n",
    "def data_generator(input_files, target_files, batch_size=32, max_shape=max_input_shape):\n",
    "    while True:\n",
    "        for i in range(0, len(input_files), batch_size):\n",
    "            input_batch = np.array([load_and_pad(os.path.join(resized_input_dir, f), max_shape) for f in input_files[i:i+batch_size]])\n",
    "            target_batch = np.array([load_and_pad(os.path.join(resized_target_dir, f), max_shape) for f in target_files[i:i+batch_size]])\n",
    "            yield (input_batch, target_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a45ad51-57bb-412c-8259-742e8d316e91",
   "metadata": {},
   "source": [
    "Making sure that the directories are correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48e38712-1523-465a-9c60-c9fe87ac7510",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-22T14:41:17.168127Z",
     "iopub.status.busy": "2023-08-22T14:41:17.167785Z",
     "iopub.status.idle": "2023-08-22T14:41:17.186347Z",
     "shell.execute_reply": "2023-08-22T14:41:17.185535Z",
     "shell.execute_reply.started": "2023-08-22T14:41:17.168100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files in /notebooks/IN+AUG: 1439\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def count_files_in_directory(directory):\n",
    "    return len([f for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f))])\n",
    "\n",
    "directory_path = resized_input_dir  # Change this to the path of your directory\n",
    "print(f\"Number of files in {directory_path}: {count_files_in_directory(directory_path)}\")\n",
    "\n",
    "directory_path = resized_target_dir  # Change this to the path of your directory\n",
    "print(f\"Number of files in {directory_path}: {count_files_in_directory(directory_path)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2263c17-531f-4dd9-a297-2f2a65d47ca7",
   "metadata": {},
   "source": [
    "## Defining Train/Validation/Test Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97605858-547b-4fe6-b375-4a4eede3b1dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-22T14:41:19.143008Z",
     "iopub.status.busy": "2023-08-22T14:41:19.142020Z",
     "iopub.status.idle": "2023-08-22T14:41:19.150044Z",
     "shell.execute_reply": "2023-08-22T14:41:19.149334Z",
     "shell.execute_reply.started": "2023-08-22T14:41:19.142981Z"
    }
   },
   "outputs": [],
   "source": [
    "indices = np.arange(len(input_files))\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "train_split = int(0.8 * len(input_files))\n",
    "val_split = int(0.9 * len(input_files))\n",
    "\n",
    "train_indices = indices[:train_split]\n",
    "val_indices = indices[train_split:val_split]\n",
    "test_indices = indices[val_split:]\n",
    "\n",
    "train_input_files = [input_files[i] for i in train_indices]\n",
    "train_target_files = [target_files[i] for i in train_indices]\n",
    "val_input_files = [input_files[i] for i in val_indices]\n",
    "val_target_files = [target_files[i] for i in val_indices]\n",
    "test_input_files = [input_files[i] for i in test_indices]\n",
    "test_target_files = [target_files[i] for i in test_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75219ad-69db-422f-81ae-0f913c384384",
   "metadata": {},
   "source": [
    "## The following are the model Hyperparameters. \n",
    "What each parameter does is described below.\n",
    "\n",
    "\n",
    "- NUM_BLOCKS -> Blocks in the encoder and decoder, for example, if NUM_BLOCKS is set to 6, there are 6 blocks in the encoder and 6 blocks in the decoder. 2D convolution, batch normalisation, and leaky ReLU layers make up each encoder block. Each decoder block includes batch normalisation, transposed 2D convolution,  potentially dropout, and ReLU layers\n",
    "- FILTER_MULTIPLIER -> Sets the number of filters in 2D convolution layers.\n",
    "- DROPOUT_ENCODER -> A list of boolean values of lengths equal to the number of blocks in the encoder. Each boolean value corresponds to a block and decides if that block should have dropout or not.\n",
    "- DROPOUT_DECODER -> A list of boolean values of lengths equal to the number of blocks in the decoder. Each boolean value corresponds to a block and decides if that block should have dropout or not.\n",
    "- DROPOUT_RATE -> Set the dropout rate in the dropout layers.\n",
    "- MASK -> Estimate a mask (and multiply it with the input) instead of estimating the output directly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37c294d2-8703-4793-ab7c-cc53f44568be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-22T14:41:19.896755Z",
     "iopub.status.busy": "2023-08-22T14:41:19.895657Z",
     "iopub.status.idle": "2023-08-22T14:41:21.566264Z",
     "shell.execute_reply": "2023-08-22T14:41:21.565510Z",
     "shell.execute_reply.started": "2023-08-22T14:41:19.896726Z"
    }
   },
   "outputs": [],
   "source": [
    "hyper_params = {\n",
    "    'NUM_BLOCKS': 6,\n",
    "    'FILTER_MULTIPLIER': 16,\n",
    "    'DROPOUT_ENCODER': [False, False, True, True, True, True],\n",
    "    'DROPOUT_DECODER': [False, False, True, True, True, True],\n",
    "    'DROPOUT_RATE': 0.5,\n",
    "    'MASK': True\n",
    "}\n",
    "\n",
    "model = unet(hyper_params)\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdaec672-8ac1-4094-88d1-842e808046d9",
   "metadata": {},
   "source": [
    "## Small test to identify the best learning rate.\n",
    "NOTE: Rerun the model after finding the appropriate LR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bfaf7730-75ab-4918-b158-b0e9dd628d26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-22T14:41:22.349309Z",
     "iopub.status.busy": "2023-08-22T14:41:22.348417Z",
     "iopub.status.idle": "2023-08-22T14:41:22.353504Z",
     "shell.execute_reply": "2023-08-22T14:41:22.352667Z",
     "shell.execute_reply.started": "2023-08-22T14:41:22.349281Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "steps_per_epoch = len(train_input_files) // batch_size\n",
    "validation_steps = len(val_input_files) // batch_size\n",
    "train_gen = data_generator(train_input_files, train_target_files, batch_size)\n",
    "val_gen = data_generator(val_input_files, val_target_files, batch_size) \n",
    "\n",
    "\n",
    "# Initialize Learning Rate Finder\n",
    "lr_finder = LearningRateFinder(min_lr=1e-6, max_lr=1e-1, steps_per_epoch=steps_per_epoch, epochs=1)\n",
    "\n",
    "# Using only 1 epoch for the Learning Rate Finder. You can use more if you want a more detailed curve.\n",
    "model.fit(train_gen, epochs=5, steps_per_epoch=steps_per_epoch, callbacks=[lr_finder])\n",
    "\n",
    "# Plot the loss against learning rates\n",
    "plot_lr_finder(lr_finder.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27268e93-28b5-48df-8908-240a81e6f0dc",
   "metadata": {},
   "source": [
    "## Begin Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71abdf2a-50ce-4f9b-9954-ffde06173fbb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-22T14:41:46.752427Z",
     "iopub.status.busy": "2023-08-22T14:41:46.751727Z",
     "iopub.status.idle": "2023-08-22T14:51:06.541074Z",
     "shell.execute_reply": "2023-08-22T14:51:06.540164Z",
     "shell.execute_reply.started": "2023-08-22T14:41:46.752400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "35/35 [==============================] - 10s 171ms/step - loss: 815.6677 - val_loss: 872.3011\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 6s 158ms/step - loss: 759.0806 - val_loss: 768.1545\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 6s 158ms/step - loss: 724.8539 - val_loss: 749.9707\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 6s 159ms/step - loss: 717.2046 - val_loss: 745.3018\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 6s 159ms/step - loss: 724.8374 - val_loss: 747.0079\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 5s 157ms/step - loss: 719.0383 - val_loss: 750.0663\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 6s 159ms/step - loss: 715.8806 - val_loss: 752.6637\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 6s 158ms/step - loss: 723.0111 - val_loss: 751.4097\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 6s 159ms/step - loss: 717.4149 - val_loss: 748.6436\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 6s 159ms/step - loss: 723.7934 - val_loss: 744.1784\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 6s 159ms/step - loss: 717.8614 - val_loss: 738.0552\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 5s 157ms/step - loss: 722.2336 - val_loss: 740.6929\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 6s 158ms/step - loss: 728.0532 - val_loss: 733.7102\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 6s 158ms/step - loss: 732.2430 - val_loss: 731.1300\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 5s 157ms/step - loss: 714.2453 - val_loss: 730.7503\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 6s 159ms/step - loss: 715.0113 - val_loss: 731.5050\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 6s 159ms/step - loss: 717.2308 - val_loss: 733.9425\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 6s 159ms/step - loss: 714.3541 - val_loss: 734.6882\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 6s 158ms/step - loss: 715.6266 - val_loss: 736.8082\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 6s 159ms/step - loss: 718.0341 - val_loss: 737.2796\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 6s 157ms/step - loss: 718.0065 - val_loss: 742.6702\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 6s 158ms/step - loss: 713.5075 - val_loss: 744.9295\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 6s 157ms/step - loss: 727.1083 - val_loss: 747.3113\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 5s 157ms/step - loss: 711.5244 - val_loss: 749.4956\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 6s 158ms/step - loss: 716.3810 - val_loss: 755.4754\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 6s 158ms/step - loss: 720.0830 - val_loss: 747.2634\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 6s 160ms/step - loss: 721.9954 - val_loss: 742.3219\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 6s 158ms/step - loss: 720.9681 - val_loss: 739.3170\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 6s 158ms/step - loss: 720.1501 - val_loss: 736.2583\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 6s 166ms/step - loss: 714.6987 - val_loss: 732.7083\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 6s 159ms/step - loss: 713.6328 - val_loss: 731.4261\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 6s 159ms/step - loss: 714.1913 - val_loss: 730.3137\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 6s 160ms/step - loss: 722.0469 - val_loss: 732.6122\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 6s 159ms/step - loss: 722.0778 - val_loss: 730.3123\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 6s 158ms/step - loss: 728.1583 - val_loss: 728.7235\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 6s 158ms/step - loss: 723.2627 - val_loss: 728.8813\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 6s 159ms/step - loss: 722.6851 - val_loss: 739.3794\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 6s 158ms/step - loss: 723.5021 - val_loss: 732.6351\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 6s 160ms/step - loss: 713.8489 - val_loss: 734.2770\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 6s 158ms/step - loss: 708.0428 - val_loss: 732.9086\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 6s 158ms/step - loss: 717.0625 - val_loss: 732.1371\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 6s 159ms/step - loss: 711.6392 - val_loss: 730.1131\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 6s 158ms/step - loss: 710.2599 - val_loss: 739.5771\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 6s 158ms/step - loss: 718.4686 - val_loss: 735.1969\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 6s 158ms/step - loss: 711.8912 - val_loss: 733.0557\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 6s 158ms/step - loss: 718.2019 - val_loss: 728.1158\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 6s 158ms/step - loss: 712.6049 - val_loss: 724.2311\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 6s 160ms/step - loss: 715.9872 - val_loss: 719.9019\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 6s 159ms/step - loss: 723.4564 - val_loss: 729.0411\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 6s 158ms/step - loss: 726.8314 - val_loss: 727.3863\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 6s 158ms/step - loss: 708.6545 - val_loss: 719.6845\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 6s 159ms/step - loss: 709.4179 - val_loss: 718.6976\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 6s 158ms/step - loss: 712.3636 - val_loss: 722.6521\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 6s 160ms/step - loss: 707.3806 - val_loss: 717.5620\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 6s 159ms/step - loss: 709.0641 - val_loss: 732.5726\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 6s 158ms/step - loss: 707.6432 - val_loss: 739.8254\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 6s 161ms/step - loss: 708.3345 - val_loss: 721.1086\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 6s 159ms/step - loss: 704.8495 - val_loss: 719.1728\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 6s 158ms/step - loss: 716.2729 - val_loss: 722.3806\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 6s 158ms/step - loss: 698.5179 - val_loss: 765.3558\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 6s 158ms/step - loss: 704.1447 - val_loss: 750.0828\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 6s 159ms/step - loss: 710.3616 - val_loss: 741.9481\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 6s 161ms/step - loss: 705.6912 - val_loss: 718.4419\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 6s 160ms/step - loss: 707.1899 - val_loss: 720.9576\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 6s 159ms/step - loss: 704.7784 - val_loss: 755.8931\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 6s 160ms/step - loss: 700.7640 - val_loss: 730.0107\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 6s 160ms/step - loss: 693.8879 - val_loss: 735.7861\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 6s 158ms/step - loss: 687.9221 - val_loss: 740.3340\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 6s 158ms/step - loss: 699.9033 - val_loss: 748.3345\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 6s 158ms/step - loss: 694.3019 - val_loss: 722.9103\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 6s 158ms/step - loss: 700.1957 - val_loss: 784.9077\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 6s 160ms/step - loss: 700.0331 - val_loss: 722.7476\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 6s 158ms/step - loss: 695.8584 - val_loss: 714.5260\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 6s 158ms/step - loss: 687.5114 - val_loss: 728.1770\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 6s 160ms/step - loss: 681.1627 - val_loss: 741.6997\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 6s 158ms/step - loss: 678.4109 - val_loss: 729.5206\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 6s 159ms/step - loss: 683.7244 - val_loss: 728.5074\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 6s 158ms/step - loss: 667.7100 - val_loss: 734.4322\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 6s 160ms/step - loss: 663.5197 - val_loss: 727.0442\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 6s 159ms/step - loss: 672.3057 - val_loss: 735.4698\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 6s 160ms/step - loss: 662.8875 - val_loss: 746.7615\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 6s 158ms/step - loss: 670.9250 - val_loss: 751.9976\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 6s 159ms/step - loss: 657.7050 - val_loss: 726.4297\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 6s 162ms/step - loss: 667.9749 - val_loss: 749.2470\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 6s 159ms/step - loss: 675.0917 - val_loss: 745.7509\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 6s 158ms/step - loss: 667.3239 - val_loss: 759.9552\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 6s 158ms/step - loss: 648.2628 - val_loss: 746.4631\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 6s 159ms/step - loss: 649.1249 - val_loss: 730.6641\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 6s 159ms/step - loss: 653.4664 - val_loss: 720.8138\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 6s 160ms/step - loss: 652.8498 - val_loss: 746.8426\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 6s 160ms/step - loss: 644.6194 - val_loss: 750.0168\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 6s 158ms/step - loss: 647.5577 - val_loss: 719.1388\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 6s 160ms/step - loss: 644.0520 - val_loss: 769.3179\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 6s 158ms/step - loss: 633.9065 - val_loss: 776.8225\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 6s 159ms/step - loss: 642.7659 - val_loss: 764.8712\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 6s 158ms/step - loss: 633.3922 - val_loss: 772.3131\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 6s 159ms/step - loss: 634.6628 - val_loss: 750.2291\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 6s 159ms/step - loss: 642.6918 - val_loss: 757.0321\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 6s 158ms/step - loss: 641.4550 - val_loss: 727.7291\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 6s 160ms/step - loss: 627.2178 - val_loss: 739.5988\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fab2c13bbe0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "batch_size = 32\n",
    "steps_per_epoch = len(train_input_files) // batch_size\n",
    "validation_steps = len(val_input_files) // batch_size\n",
    "train_gen = data_generator(train_input_files, train_target_files, batch_size)\n",
    "val_gen = data_generator(val_input_files, val_target_files, batch_size)\n",
    "\n",
    "# Set up ReduceLROnPlateau callback\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-6)\n",
    "\n",
    "# Add Early Stopping callback\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, verbose=1, restore_best_weights=True)\n",
    "\n",
    "model.fit(train_gen,\n",
    "          steps_per_epoch=steps_per_epoch,\n",
    "          epochs=100,\n",
    "          validation_data=val_gen,\n",
    "          validation_steps=validation_steps,\n",
    "          callbacks = early_stopping, reduce_lr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a33df1-84bf-4ea8-a2ca-f988f269da5e",
   "metadata": {},
   "source": [
    "## Test Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "64dd11ca-fa7e-47ec-afff-6363083fffbb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-22T14:51:18.242318Z",
     "iopub.status.busy": "2023-08-22T14:51:18.241931Z",
     "iopub.status.idle": "2023-08-22T14:51:18.639067Z",
     "shell.execute_reply": "2023-08-22T14:51:18.637772Z",
     "shell.execute_reply.started": "2023-08-22T14:51:18.242293Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 67ms/step - loss: 882.1355\n",
      "Test Loss: 882.1355\n"
     ]
    }
   ],
   "source": [
    "test_gen = data_generator(test_input_files, test_target_files, batch_size)\n",
    "loss = model.evaluate(test_gen, steps=len(test_input_files) // batch_size)\n",
    "print(f\"Test Loss: {loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f71166-7810-4715-967e-361546f67081",
   "metadata": {},
   "source": [
    "## Main Evaluation Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "02a8b1b6-92f3-4047-bfd7-ab90d4d8e64b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-22T14:51:20.315092Z",
     "iopub.status.busy": "2023-08-22T14:51:20.314728Z",
     "iopub.status.idle": "2023-08-22T14:51:25.774549Z",
     "shell.execute_reply": "2023-08-22T14:51:25.773713Z",
     "shell.execute_reply.started": "2023-08-22T14:51:20.315068Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 337ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1675/3029162740.py:7: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  interference = true_frame - (np.dot(true_frame, predicted_frame) / np.dot(predicted_frame, predicted_frame)) * predicted_frame\n",
      "/tmp/ipykernel_1675/3029162740.py:14: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  interference = true_frame - (np.dot(true_frame, predicted_frame) / np.dot(predicted_frame, predicted_frame)) * predicted_frame\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Average Test SDR: -7.3551\n",
      "Average Test SIR: nan\n",
      "Average Test SAR: nan\n"
     ]
    }
   ],
   "source": [
    "SDRs, SIRs, SARs = [], [], []\n",
    "\n",
    "# Iterate over test dataset to compute the metrics:\n",
    "for i, (inputs, targets) in enumerate(test_gen):\n",
    "    if i == len(test_input_files) // batch_size:\n",
    "        break\n",
    "    predictions = model.predict(inputs)\n",
    "    for true_signal, predicted_signal in zip(targets, predictions):\n",
    "        SDRs.append(compute_metric_for_signal(true_signal, predicted_signal, compute_SDR_frame))\n",
    "        SIRs.append(compute_metric_for_signal(true_signal, predicted_signal, compute_SIR_frame))\n",
    "        SARs.append(compute_metric_for_signal(true_signal, predicted_signal, compute_SAR_frame))\n",
    "\n",
    "# Calculate average metrics for the entire test set:\n",
    "average_SDR = np.mean(SDRs)\n",
    "average_SIR = np.mean(SIRs)\n",
    "average_SAR = np.mean(SARs)\n",
    "\n",
    "print(f\"Average Test SDR: {average_SDR:.4f}\")\n",
    "print(f\"Average Test SIR: {average_SIR:.4f}\")\n",
    "print(f\"Average Test SAR: {average_SAR:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
